Now, I will introduce the discussion section. As we mentioned before, our project on Hand Pose Recognition is divided into two parts: hand detection and hand pose recognition. We used two different models for these tasks which are YOLOv3 and MobileNetv2
For hand detection, we chose the YOLOv3 model, the reason is that it a classic algorithm for object detection using neural networks. It's known for its feature pyramid network, which has high accuracy and speed. It is capable of detecting objects in various environments and scenes. However, it does have some limitations, particularly when dealing with small objects due to their small number of pixel points. Also, It Uses a meshing method rather than a pixel-level method, resulting in poor performance in dealing with target edges. Additionally, YOLOv3 is pretty complicated, it requires a large number of parameters to be trained, which can be time-consuming and resource-intensive.
Consider the larger number of training data and limited time, we choose MobileNetv2 for the second task which is hand pose recognition. As a neural network, MobileNetv2 is smaller, faster, and requires significantly fewer parameters than larger networks like YOLOv3. In other words, it requires less memory and computational effort than classic large networks.

However, our model does have some limitations. For the Handpose Recognition task, While it performs well on images with clear hand contours, it struggles with images with unclear hand contours or those taken from specific angles.
Future work will focus on optimizing the model to improve its performance on these challenging images. This could involve increasing the number of epochs, using more training data, improving the model's generalization ability, or exploring different models if resources and time satisfied.

That's our presentation, thank you.



