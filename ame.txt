Now, I will introduce the discussion section. As we mentioned before, our project on Hand Pose Recognition is divided into two parts: hand detection and hand pose recognition. We used two different models for these tasks which are YOLOv3 and MobileNetv2
For hand detection, we chose the YOLOv3 model, the reason is that it a classic algorithm for object detection using neural networks. It's known for its feature pyramid network, which has high accuracy and speed. It is capable of detecting objects in various environments and scenes. However, it does have some limitations, particularly when dealing with small objects due to their small number of pixel points. Also, It Uses a meshing method rather than a pixel-level method, resulting in poor performance in dealing with target edges. Additionally, YOLOv3 is pretty complicated, it requires a large number of parameters to be trained, which can be time-consuming and resource-intensive.
Consider the larger number of training data and limited time, we choose MobileNetv2 for the second task which is hand pose recognition. As a neural network, MobileNetv2 is smaller, faster, and requires significantly fewer parameters than larger networks like YOLOv3. In other words, it requires less memory and computational effort than classic large networks.

However, our model does have some limitations. For the Handpose Recognition task, While it performs well on images with clear hand contours, it struggles with images with unclear hand contours or those taken from specific angles.
Future work will focus on optimizing the model to improve its performance on these challenging images. This could involve increasing the number of epochs, using more training data, improving the model's generalization ability, or exploring different models if resources and time satisfied.

That's our presentation, thank you.



Document 0:::
Create an Endpoint

After your first login, you will be directed to the [Endpoint creation page](https://ui.endpoints.huggingface.co/new). As an example, this guide will go through the steps to deploy [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) for text classification.

## 1. Enter the Hugging Face Repository ID and your desired endpoint name:

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_repository.png" alt="select repository" />

## 2. Select your Cloud Provider and region. Initially, only AWS will be available as a Cloud Provider with the `us-east-1` and `eu-west-1` regions. We will add Azure soon, and if you need to test Endpoints with other Cloud Providers or regions, please let us know.

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_region.png" alt="select region" />

## 3. Define the [Security Level](security) for the Endpoint:

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_security.png" alt="define security" />

## 4. Create your Endpoint by clicking **Create Endpoint**. By default, your Endpoint is created with a medium CPU (2 x 4GB vCPUs with Intel Xeon Ice Lake) The cost estimate assumes the Endpoint will be up for an entire month, and does not take autoscaling into account.Document 1:::
<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_create_cost.png" alt="create endpoint" />

## 5. Wait for the Endpoint to build, initialize and run which can take between 1 to 5 minutes.

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/overview.png" alt="overview" />

## 6. Test your Endpoint in the overview with the Inference widget ğŸ ğŸ‰!

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_inference.png" alt="run inference" />Document 2:::
- `NUMBA_CACHE_DIR`: directory where the `numba` decorators (used by `librosa`) can write cache.

Note that this directory will be appended to `WORKER_STORAGE_PATHS` (see [../../libs/libcommon/README.md](../../libs/libcommon/README.md)) to hold the workers when the disk is full.

### Huggingface_hub library

If the Hub is not https://huggingface.co (i.e., if you set the `COMMON_HF_ENDPOINT` environment variable), you must set the `HF_ENDPOINT` environment variable to the same value. See https://github.com/huggingface/datasets/pull/5196#issuecomment-1322191411 for more details:

- `HF_ENDPOINT`: the URL of the Hub. Defaults to `https://huggingface.co`.

### First rows worker

Set environment variables to configure the `first-rows` worker (`FIRST_ROWS_` prefix):Document 3:::
```

ç›¸åï¼Œè¿™é‡Œæˆ‘ä»¬ä¿ç•™å›¾åƒçš„åŸå§‹å¤§å°ï¼Œä½†åœ¨å°†å…¶è½¬æ¢ä¸º numpy æ•°ç»„ä¹‹å‰åè½¬é¢œè‰²ï¼š

```py
img = gr.Image(invert_colors=True, type="numpy")
```

åå¤„ç†è¦å®¹æ˜“å¾—å¤šï¼Gradio è‡ªåŠ¨è¯†åˆ«è¿”å›æ•°æ®çš„æ ¼å¼ï¼ˆä¾‹å¦‚ `Image` æ˜¯ `numpy` æ•°ç»„è¿˜æ˜¯ `str` æ–‡ä»¶è·¯å¾„ï¼Ÿï¼‰ï¼Œå¹¶å°†å…¶åå¤„ç†ä¸ºå¯ä»¥ç”±æµè§ˆå™¨æ˜¾ç¤ºçš„æ ¼å¼ã€‚

è¯·æŸ¥çœ‹[æ–‡æ¡£](https://gradio.app/docs)ï¼Œäº†è§£æ¯ä¸ªç»„ä»¶çš„æ‰€æœ‰ä¸é¢„å¤„ç†ç›¸å…³çš„å‚æ•°ã€‚

## æ ·å¼ (Styling)

Gradio ä¸»é¢˜æ˜¯è‡ªå®šä¹‰åº”ç”¨ç¨‹åºå¤–è§‚å’Œæ„Ÿè§‰çš„æœ€ç®€å•æ–¹æ³•ã€‚æ‚¨å¯ä»¥é€‰æ‹©å¤šç§ä¸»é¢˜æˆ–åˆ›å»ºè‡ªå·±çš„ä¸»é¢˜ã€‚è¦è¿™æ ·åšï¼Œè¯·å°† `theme=` å‚æ•°ä¼ é€’ç»™ `Interface` æ„é€ å‡½æ•°ã€‚ä¾‹å¦‚ï¼š

```python
demo = gr.Interface(..., theme=gr.themes.Monochrome())
```

Gradio å¸¦æœ‰ä¸€ç»„é¢„å…ˆæ„å»ºçš„ä¸»é¢˜ï¼Œæ‚¨å¯ä»¥ä» `gr.themes.*` åŠ è½½ã€‚æ‚¨å¯ä»¥æ‰©å±•è¿™äº›ä¸»é¢˜æˆ–ä»å¤´å¼€å§‹åˆ›å»ºè‡ªå·±çš„ä¸»é¢˜ - æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[ä¸»é¢˜æŒ‡å—](https://gradio.app/theming-guide)ã€‚

è¦å¢åŠ é¢å¤–çš„æ ·å¼èƒ½åŠ›ï¼Œæ‚¨å¯ä»¥ with `css=` å…³é”®å­—å°†ä»»ä½• CSS ä¼ é€’ç»™æ‚¨çš„åº”ç”¨ç¨‹åºã€‚
Gradio åº”ç”¨ç¨‹åºçš„åŸºç±»æ˜¯ `gradio-container`ï¼Œå› æ­¤ä»¥ä¸‹æ˜¯ä¸€ä¸ªæ›´æ”¹ Gradio åº”ç”¨ç¨‹åºèƒŒæ™¯é¢œè‰²çš„ç¤ºä¾‹ï¼š

```python
with `gr.Interface(css=".gradio-container {background-color: red}") as demo:
    ...Document 4:::
```

æ‚¨ä»¥ä¸å¸¸è§„å‡½æ•°ç›¸åŒçš„æ–¹å¼å°†ç”Ÿæˆå™¨æä¾›ç»™ Gradioã€‚ä¾‹å¦‚ï¼Œè¿™æ˜¯ä¸€ä¸ªï¼ˆè™šæ‹Ÿçš„ï¼‰å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå®ƒåœ¨è¾“å‡ºå›¾åƒä¹‹å‰ç”Ÿæˆæ•°ä¸ªæ­¥éª¤çš„å™ªéŸ³ï¼š

$code_fake_diffusion
$demo_fake_diffusion

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨è¿­ä»£å™¨ä¸­æ·»åŠ äº† `time.sleep(1)`ï¼Œä»¥åˆ›å»ºæ­¥éª¤ä¹‹é—´çš„äººå·¥æš‚åœï¼Œä»¥ä¾¿æ‚¨å¯ä»¥è§‚å¯Ÿè¿­ä»£å™¨çš„æ­¥éª¤ï¼ˆåœ¨çœŸå®çš„å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­ï¼Œè¿™å¯èƒ½æ˜¯ä¸å¿…è¦çš„ï¼‰ã€‚

å°†ç”Ÿæˆå™¨æä¾›ç»™ Gradio **éœ€è¦**åœ¨åº•å±‚ Interface æˆ– Blocks ä¸­å¯ç”¨é˜Ÿåˆ—ï¼ˆè¯·å‚é˜…ä¸Šé¢çš„é˜Ÿåˆ—éƒ¨åˆ†ï¼‰ã€‚

## è¿›åº¦æ¡

Gradio æ”¯æŒåˆ›å»ºè‡ªå®šä¹‰è¿›åº¦æ¡ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥è‡ªå®šä¹‰å’Œæ§åˆ¶å‘ç”¨æˆ·æ˜¾ç¤ºçš„è¿›åº¦æ›´æ–°ã€‚è¦å¯ç”¨æ­¤åŠŸèƒ½ï¼Œåªéœ€ä¸ºæ–¹æ³•æ·»åŠ ä¸€ä¸ªé»˜è®¤å€¼ä¸º `gr.Progress` å®ä¾‹çš„å‚æ•°å³å¯ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ç›´æ¥è°ƒç”¨æ­¤å®ä¾‹å¹¶ä¼ å…¥ 0 åˆ° 1 ä¹‹é—´çš„æµ®ç‚¹æ•°æ¥æ›´æ–°è¿›åº¦çº§åˆ«ï¼Œæˆ–è€… with `Progress` å®ä¾‹çš„ `tqdm()` æ–¹æ³•æ¥è·Ÿè¸ªå¯è¿­ä»£å¯¹è±¡ä¸Šçš„è¿›åº¦ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚å¿…é¡»å¯ç”¨é˜Ÿåˆ—ä»¥è¿›è¡Œè¿›åº¦æ›´æ–°ã€‚

$code_progress_simple
$demo_progress_simple

å¦‚æœæ‚¨ with `tqdm` åº“ï¼Œå¹¶ä¸”å¸Œæœ›ä»å‡½æ•°å†…éƒ¨çš„ä»»ä½• `tqdm.tqdm` è‡ªåŠ¨æŠ¥å‘Šè¿›åº¦æ›´æ–°ï¼Œè¯·å°†é»˜è®¤å‚æ•°è®¾ç½®ä¸º `gr.Progress(track_tqdm=True)`ï¼

## æ‰¹å¤„ç†å‡½æ•° (Batch Functions)

Gradio æ”¯æŒä¼ é€’*æ‰¹å¤„ç†*å‡½æ•°ã€‚æ‰¹å¤„ç†å‡½æ•°åªæ˜¯æ¥å—è¾“å…¥åˆ—è¡¨å¹¶è¿”å›é¢„æµ‹åˆ—è¡¨çš„å‡½æ•°ã€‚



Extracted documents:
Document 0:::
<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_create_cost.png" alt="create endpoint" />

## 5. Wait for the Endpoint to build, initialize and run which can take between 1 to 5 minutes.

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/overview.png" alt="overview" />

## 6. Test your Endpoint in the overview with the Inference widget ğŸ ğŸ‰!

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_inference.png" alt="run inference" />Document 1:::
Create an Endpoint

After your first login, you will be directed to the [Endpoint creation page](https://ui.endpoints.huggingface.co/new). As an example, this guide will go through the steps to deploy [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) for text classification.

## 1. Enter the Hugging Face Repository ID and your desired endpoint name:

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_repository.png" alt="select repository" />

## 2. Select your Cloud Provider and region. Initially, only AWS will be available as a Cloud Provider with the `us-east-1` and `eu-west-1` regions. We will add Azure soon, and if you need to test Endpoints with other Cloud Providers or regions, please let us know.

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_region.png" alt="select region" />

## 3. Define the [Security Level](security) for the Endpoint:

<img src="https://raw.githubusercontent.com/huggingface/hf-endpoints-documentation/main/assets/1_security.png" alt="define security" />

## 4. Create your Endpoint by clicking **Create Endpoint**. By default, your Endpoint is created with a medium CPU (2 x 4GB vCPUs with Intel Xeon Ice Lake) The cost estimate assumes the Endpoint will be up for an entire month, and does not take autoscaling into account.Document 2:::
```

æ‚¨ä»¥ä¸å¸¸è§„å‡½æ•°ç›¸åŒçš„æ–¹å¼å°†ç”Ÿæˆå™¨æä¾›ç»™ Gradioã€‚ä¾‹å¦‚ï¼Œè¿™æ˜¯ä¸€ä¸ªï¼ˆè™šæ‹Ÿçš„ï¼‰å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå®ƒåœ¨è¾“å‡ºå›¾åƒä¹‹å‰ç”Ÿæˆæ•°ä¸ªæ­¥éª¤çš„å™ªéŸ³ï¼š

$code_fake_diffusion
$demo_fake_diffusion

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨è¿­ä»£å™¨ä¸­æ·»åŠ äº† `time.sleep(1)`ï¼Œä»¥åˆ›å»ºæ­¥éª¤ä¹‹é—´çš„äººå·¥æš‚åœï¼Œä»¥ä¾¿æ‚¨å¯ä»¥è§‚å¯Ÿè¿­ä»£å™¨çš„æ­¥éª¤ï¼ˆåœ¨çœŸå®çš„å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­ï¼Œè¿™å¯èƒ½æ˜¯ä¸å¿…è¦çš„ï¼‰ã€‚

å°†ç”Ÿæˆå™¨æä¾›ç»™ Gradio **éœ€è¦**åœ¨åº•å±‚ Interface æˆ– Blocks ä¸­å¯ç”¨é˜Ÿåˆ—ï¼ˆè¯·å‚é˜…ä¸Šé¢çš„é˜Ÿåˆ—éƒ¨åˆ†ï¼‰ã€‚

## è¿›åº¦æ¡

Gradio æ”¯æŒåˆ›å»ºè‡ªå®šä¹‰è¿›åº¦æ¡ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥è‡ªå®šä¹‰å’Œæ§åˆ¶å‘ç”¨æˆ·æ˜¾ç¤ºçš„è¿›åº¦æ›´æ–°ã€‚è¦å¯ç”¨æ­¤åŠŸèƒ½ï¼Œåªéœ€ä¸ºæ–¹æ³•æ·»åŠ ä¸€ä¸ªé»˜è®¤å€¼ä¸º `gr.Progress` å®ä¾‹çš„å‚æ•°å³å¯ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ç›´æ¥è°ƒç”¨æ­¤å®ä¾‹å¹¶ä¼ å…¥ 0 åˆ° 1 ä¹‹é—´çš„æµ®ç‚¹æ•°æ¥æ›´æ–°è¿›åº¦çº§åˆ«ï¼Œæˆ–è€… with `Progress` å®ä¾‹çš„ `tqdm()` æ–¹æ³•æ¥è·Ÿè¸ªå¯è¿­ä»£å¯¹è±¡ä¸Šçš„è¿›åº¦ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚å¿…é¡»å¯ç”¨é˜Ÿåˆ—ä»¥è¿›è¡Œè¿›åº¦æ›´æ–°ã€‚

$code_progress_simple
$demo_progress_simple

å¦‚æœæ‚¨ with `tqdm` åº“ï¼Œå¹¶ä¸”å¸Œæœ›ä»å‡½æ•°å†…éƒ¨çš„ä»»ä½• `tqdm.tqdm` è‡ªåŠ¨æŠ¥å‘Šè¿›åº¦æ›´æ–°ï¼Œè¯·å°†é»˜è®¤å‚æ•°è®¾ç½®ä¸º `gr.Progress(track_tqdm=True)`ï¼

## æ‰¹å¤„ç†å‡½æ•° (Batch Functions)

Gradio æ”¯æŒä¼ é€’*æ‰¹å¤„ç†*å‡½æ•°ã€‚æ‰¹å¤„ç†å‡½æ•°åªæ˜¯æ¥å—è¾“å…¥åˆ—è¡¨å¹¶è¿”å›é¢„æµ‹åˆ—è¡¨çš„å‡½æ•°ã€‚Document 3:::
```

ç›¸åï¼Œè¿™é‡Œæˆ‘ä»¬ä¿ç•™å›¾åƒçš„åŸå§‹å¤§å°ï¼Œä½†åœ¨å°†å…¶è½¬æ¢ä¸º numpy æ•°ç»„ä¹‹å‰åè½¬é¢œè‰²ï¼š

```py
img = gr.Image(invert_colors=True, type="numpy")
```

åå¤„ç†è¦å®¹æ˜“å¾—å¤šï¼Gradio è‡ªåŠ¨è¯†åˆ«è¿”å›æ•°æ®çš„æ ¼å¼ï¼ˆä¾‹å¦‚ `Image` æ˜¯ `numpy` æ•°ç»„è¿˜æ˜¯ `str` æ–‡ä»¶è·¯å¾„ï¼Ÿï¼‰ï¼Œå¹¶å°†å…¶åå¤„ç†ä¸ºå¯ä»¥ç”±æµè§ˆå™¨æ˜¾ç¤ºçš„æ ¼å¼ã€‚

è¯·æŸ¥çœ‹[æ–‡æ¡£](https://gradio.app/docs)ï¼Œäº†è§£æ¯ä¸ªç»„ä»¶çš„æ‰€æœ‰ä¸é¢„å¤„ç†ç›¸å…³çš„å‚æ•°ã€‚

## æ ·å¼ (Styling)

Gradio ä¸»é¢˜æ˜¯è‡ªå®šä¹‰åº”ç”¨ç¨‹åºå¤–è§‚å’Œæ„Ÿè§‰çš„æœ€ç®€å•æ–¹æ³•ã€‚æ‚¨å¯ä»¥é€‰æ‹©å¤šç§ä¸»é¢˜æˆ–åˆ›å»ºè‡ªå·±çš„ä¸»é¢˜ã€‚è¦è¿™æ ·åšï¼Œè¯·å°† `theme=` å‚æ•°ä¼ é€’ç»™ `Interface` æ„é€ å‡½æ•°ã€‚ä¾‹å¦‚ï¼š

```python
demo = gr.Interface(..., theme=gr.themes.Monochrome())
```

Gradio å¸¦æœ‰ä¸€ç»„é¢„å…ˆæ„å»ºçš„ä¸»é¢˜ï¼Œæ‚¨å¯ä»¥ä» `gr.themes.*` åŠ è½½ã€‚æ‚¨å¯ä»¥æ‰©å±•è¿™äº›ä¸»é¢˜æˆ–ä»å¤´å¼€å§‹åˆ›å»ºè‡ªå·±çš„ä¸»é¢˜ - æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[ä¸»é¢˜æŒ‡å—](https://gradio.app/theming-guide)ã€‚

è¦å¢åŠ é¢å¤–çš„æ ·å¼èƒ½åŠ›ï¼Œæ‚¨å¯ä»¥ with `css=` å…³é”®å­—å°†ä»»ä½• CSS ä¼ é€’ç»™æ‚¨çš„åº”ç”¨ç¨‹åºã€‚
Gradio åº”ç”¨ç¨‹åºçš„åŸºç±»æ˜¯ `gradio-container`ï¼Œå› æ­¤ä»¥ä¸‹æ˜¯ä¸€ä¸ªæ›´æ”¹ Gradio åº”ç”¨ç¨‹åºèƒŒæ™¯é¢œè‰²çš„ç¤ºä¾‹ï¼š

```python
with `gr.Interface(css=".gradio-container {background-color: red}") as demo:
    ...Document 4:::
and tokenizer, we applied the tokenization to all the dataset with padding and truncation to make all samples of length 128. As a result, if we pas

my name is fancy, im the author of this product.
